{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re \n",
    "from typing import Optional\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import holidays\n",
    "import yfinance as yf\n",
    "from tqdm.notebook import tqdm\n",
    "from itertools import tee\n",
    "from datetime import datetime, timedelta\n",
    "from gp import GPTiny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def GetDatePairs(start,end):\n",
    "    us_holidays = holidays.financial_holidays('NYSE') \n",
    "    daterange = pd.bdate_range(start=start,end=end)\n",
    "    daterange = [c for c in daterange if c not in us_holidays]\n",
    "    a1, a2 = tee(daterange)\n",
    "    next(a2)\n",
    "    pairs = list((z[0].to_pydatetime(),z[1].to_pydatetime()) for z in zip(a1, a2))\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"./data\", exist_ok=True)\n",
    "os.makedirs(\"./dailies\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = None\n",
    "existingfiles = sorted(Path('./dailies').iterdir(), key=lambda f: f.stat().st_mtime)\n",
    "latestfile = [str(f) for f in existingfiles if \"top\" in (str(f)) ]\n",
    "x = re.search(r'(\\d+[-]\\d+[-]\\d+)', latestfile[-1]) \n",
    "\n",
    "if(x is None):\n",
    "    B = GetDatePairs(start='2024-11-01',end=(datetime.today()).strftime(\"%Y-%m-%d\"))\n",
    "    \n",
    "else:\n",
    "    B = GetDatePairs(start=x.group(0),end=(datetime.today()).strftime(\"%Y-%m-%d\"))\n",
    "    \n",
    "print(f\"Start: {B[0][0]}, End:{B[-1][1]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_data=requests.get('https://en.wikipedia.org/wiki/List_of_S%26P_500_companies').text\n",
    "beautiful_soup=BeautifulSoup(html_data, \"html.parser\")\n",
    "tables = beautiful_soup.find_all('table')\n",
    "S_P_500_companies = list([])\n",
    "\n",
    "for row in tables[0].tbody.find_all(\"tr\"):\n",
    "    col = row.find_all(\"td\")\n",
    "    if (col != []):\n",
    "        Symbol = col[0].text.strip().replace('\\n','')\n",
    "        Security = col[1].text.strip().replace('\\n','')\n",
    "        Sector = col[2].text.strip().replace('\\n','')\n",
    "        Sub_Industry = col[3].text.strip().replace('\\n','')\n",
    "        Headquarters_Location = col[4].text.strip().replace('\\n','')\n",
    "        Date_first = col[5].text.strip().replace('\\n','')\n",
    "        CIK = col[6].text.strip().replace('\\n','')\n",
    "        Founded = col[7].text.strip().replace('\\n','')\n",
    "        S_P_500_companies.append({\"Symbol\":Symbol, \"Security\":Security, \"Sector\":Sector, \"Sub-Industry\":Sub_Industry,\n",
    "          \"Headquarters\":Headquarters_Location,\"Date-Added\":Date_first,\"CIK\":CIK,\"Founded\":Founded})\n",
    "snp500 = pd.DataFrame(data=S_P_500_companies)\n",
    "snp500.Symbol = snp500.Symbol.str.replace('.','-') \n",
    "snp500.to_csv('./data/sp500_companies.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MungeData(sym, spy, start, end):\n",
    "    try:\n",
    "        if(spy is None):\n",
    "            stock = yf.Ticker('^GSPC')\n",
    "            stockhist = stock.history(start=start,end=end)\n",
    "            spy = stockhist[['Open', 'High', 'Low', 'Close', 'Volume']].copy().pct_change(fill_method=None)+1\n",
    "\n",
    "        stock = yf.Ticker(sym)\n",
    "        stockhist = stock.history(start=start,end=end)\n",
    "        x = stockhist[['Open', 'High', 'Low', 'Close', 'Volume']].copy().pct_change(fill_method=None)+1\n",
    "        x /= spy\n",
    "        x = np.log(x)\n",
    "        x.insert(0,'Days',(x.index-x.index[0]).days)\n",
    "        for c in ['Open','Close','High','Low','Volume']:\n",
    "            x[c+'_Div'] = x[c].diff()/x['Days'].diff()\n",
    "            x[c+'_Div2'] = x[c+'_Div'].diff()/x['Days'].diff()\n",
    "            for i in [7,14,21,28]:\n",
    "                x[c+'_'+str(i)+'_MN'] = x[c].rolling(pd.Timedelta(days=i)).mean()\n",
    "                x[c+'_'+str(i)+'_SD'] = (x[c].rolling(pd.Timedelta(days=i)).std())\n",
    "\n",
    "        _ = x.pop('Days')\n",
    "        x.insert(0,\"Sym\",sym)\n",
    "        x['Target'] = x.groupby('Sym').Close.shift(-1).fillna(-999)\n",
    "        x.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "        x.dropna(inplace=True)\n",
    "        \n",
    "        return x, spy\n",
    "    except:\n",
    "        return None, spy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = B[0][0].strftime(\"%Y-%m-%d\")\n",
    "end = B[-1][1].strftime(\"%Y-%m-%d\")\n",
    "print(start,end)\n",
    "spy = None\n",
    "g = []\n",
    "for c in tqdm(list(snp500.Symbol.values)):\n",
    "\n",
    "    l,spy = MungeData(c, spy, (datetime.strptime(start,\"%Y-%m-%d\")-timedelta(weeks=5)).strftime(\"%Y-%m-%d\"), end)#Requred to ensure all  rolling values are populated\n",
    "    \n",
    "    if l is not None:\n",
    "        g.append(l)\n",
    "  \n",
    "o= pd.concat(g, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpModel = GPTiny()\n",
    "for start, end in tqdm(B):\n",
    "    filepath = Path('./dailies/top_close_'+start.strftime(\"%Y-%m-%d\")+'_'+end.strftime(\"%Y-%m-%d\")+'.csv')\n",
    "    if(False==filepath.is_file()):\n",
    "        print(start.strftime(\"%Y-%m-%d\"),end.strftime(\"%Y-%m-%d\"))\n",
    "        mask = (o.index >= start.strftime(\"%Y-%m-%d\")) & (o.index < end.strftime(\"%Y-%m-%d\"))\n",
    "        x = o[mask].copy()\n",
    "        print(x.shape)\n",
    "        wset = []\n",
    "        lset = []\n",
    "        if(x.shape[0]>0):\n",
    "            #print(x.shape)\n",
    "            for gp in range(10):\n",
    "                t = x[['Sym']].copy()\n",
    "                if(gp==0):\n",
    "                    t['Target'] = gpModel.GPI(x)\n",
    "                elif(gp==1):\n",
    "                    t['Target'] = gpModel.GPII(x)\n",
    "                elif(gp==2):\n",
    "                    t['Target'] = gpModel.GPIII(x)\n",
    "                elif(gp==3):\n",
    "                    t['Target'] = gpModel.GPIV(x)\n",
    "                elif(gp==4):\n",
    "                    t['Target'] = gpModel.GPV(x)\n",
    "                if(gp==5):\n",
    "                    t['Target'] = gpModel.GPVI(x)\n",
    "                elif(gp==6):\n",
    "                    t['Target'] = gpModel.GPVII(x)\n",
    "                elif(gp==7):\n",
    "                    t['Target'] = gpModel.GPVIII(x)\n",
    "                elif(gp==8):\n",
    "                    t['Target'] = gpModel.GPIX(x)\n",
    "                else:\n",
    "                    t['Target'] = gpModel.GPX(x)\n",
    "\n",
    "                w = t.reset_index().pivot(index='Date',columns='Sym',values='Target')\n",
    "\n",
    "                w1 = pd.DataFrame({n: w.T[col].nlargest(200).index.tolist() \n",
    "                                for n, col in enumerate(w.T)}).T\n",
    "                l1 = pd.DataFrame({n: w.T[col].nsmallest(200).index.tolist() \n",
    "                                for n, col in enumerate(w.T)}).T\n",
    "                wset.append(w1.values[0])\n",
    "                lset.append(l1.values[0])    \n",
    "\n",
    "                \n",
    "            wsubset = pd.DataFrame(data={'Sym':list(set.intersection(*map(set,wset)))})\n",
    "            lsubset = pd.DataFrame(data={'Sym':list(set.intersection(*map(set,lset)))})\n",
    "\n",
    "            wstd = {}\n",
    "            lstd = {}\n",
    "            for sym in wsubset.Sym.values:\n",
    "                mask = (o.index >= start.strftime(\"%Y-%m-%d\")) & (o.index < end.strftime(\"%Y-%m-%d\"))\n",
    "                x = o[mask].copy()\n",
    "                x = x[x['Sym'] == sym]\n",
    "                v = [gpModel.GPI(x),gpModel.GPII(x),gpModel.GPIII(x),gpModel.GPIV(x),gpModel.GPV(x),\n",
    "                     gpModel.GPVI(x),gpModel.GPVII(x),gpModel.GPVIII(x),gpModel.GPIX(x),gpModel.GPX(x)]\n",
    "                wstd[sym] = [np.std(v),np.min(v),np.mean(v),np.max(v)]\n",
    "            for sym in lsubset.Sym.values:\n",
    "                mask = (o.index >= start.strftime(\"%Y-%m-%d\")) & (o.index < end.strftime(\"%Y-%m-%d\"))\n",
    "                x = o[mask].copy()\n",
    "                x = x[x['Sym'] == sym]\n",
    "                v = [gpModel.GPI(x),gpModel.GPII(x),gpModel.GPIII(x),gpModel.GPIV(x),gpModel.GPV(x),\n",
    "                     gpModel.GPVI(x),gpModel.GPVII(x),gpModel.GPVIII(x),gpModel.GPIX(x),gpModel.GPX(x)]\n",
    "                lstd[sym] = [np.std(v),np.min(v),np.mean(v),np.max(v)]\n",
    "        \n",
    "            w = pd.DataFrame.from_dict(wstd,orient='index',columns=['Std','Mi','Mn','Ma'])\n",
    "            w.index.name = 'Sym'\n",
    "            w.to_csv('./dailies/top_close_'+start.strftime(\"%Y-%m-%d\")+'_'+end.strftime(\"%Y-%m-%d\")+'.csv')\n",
    "            l = pd.DataFrame.from_dict(lstd,orient='index',columns=['Std','Mi','Mn','Ma'])\n",
    "            l.index.name = 'Sym'\n",
    "            l.to_csv('./dailies/bottom_close_'+start.strftime(\"%Y-%m-%d\")+'_'+end.strftime(\"%Y-%m-%d\")+'.csv')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start, end = B[-1]\n",
    "print(start,end)\n",
    "bottom = pd.read_csv('./dailies/bottom_close_'+start.strftime(\"%Y-%m-%d\")+'_'+end.strftime(\"%Y-%m-%d\")+'.csv')\n",
    "top = pd.read_csv('./dailies/top_close_'+start.strftime(\"%Y-%m-%d\")+'_'+end.strftime(\"%Y-%m-%d\")+'.csv')\n",
    "print(\"Top:\")\n",
    "if(len(top.Sym)):\n",
    "    print('https://uk.finance.yahoo.com/quote/{0}/'.format(','.join(top.Sym.values)))\n",
    "else:\n",
    "    print(\"No Recommendations\")\n",
    "print(\"Bottom:\")\n",
    "if(len(bottom.Sym)):\n",
    "    print('https://uk.finance.yahoo.com/quote/{0}/'.format(','.join(bottom.Sym.values)))\n",
    "else:\n",
    "    print(\"No Recommendations\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
