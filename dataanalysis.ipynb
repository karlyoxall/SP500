{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T12:54:44.981941075Z",
     "start_time": "2026-01-24T12:54:44.808282814Z"
    }
   },
   "source": [
    "import os\n",
    "import re \n",
    "from typing import Optional\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import holidays\n",
    "import yfinance as yf\n",
    "from tqdm.notebook import tqdm\n",
    "from itertools import tee\n",
    "from datetime import datetime, timedelta\n",
    "from gp import GPTiny"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T12:54:45.308860014Z",
     "start_time": "2026-01-24T12:54:45.279917092Z"
    }
   },
   "source": [
    "\n",
    "def GetDatePairs(start,end):\n",
    "    us_holidays = holidays.financial_holidays('NYSE') \n",
    "    daterange = pd.bdate_range(start=start,end=end)\n",
    "    daterange = [c for c in daterange if c not in us_holidays]\n",
    "    a1, a2 = tee(daterange)\n",
    "    next(a2)\n",
    "    pairs = list((z[0].to_pydatetime(),z[1].to_pydatetime()) for z in zip(a1, a2))\n",
    "    return pairs"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T12:54:45.752231974Z",
     "start_time": "2026-01-24T12:54:45.731879915Z"
    }
   },
   "source": [
    "os.makedirs(\"./data_test\", exist_ok=True)\n",
    "os.makedirs(\"./dailies_test\", exist_ok=True)"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T12:54:46.191762955Z",
     "start_time": "2026-01-24T12:54:46.140263274Z"
    }
   },
   "source": [
    "B = None\n",
    "existingfiles = sorted(Path('./dailies_test').iterdir(), key=lambda f: f.stat().st_mtime)\n",
    "latestfile = [str(f) for f in existingfiles if \"top\" in (str(f)) ]\n",
    "x = None#re.search(r'(\\d+[-]\\d+[-]\\d+)', latestfile[-1])\n",
    "\n",
    "if(x is None):\n",
    "    B = GetDatePairs(start='2024-11-01',end=(datetime.today()).strftime(\"%Y-%m-%d\"))\n",
    "    \n",
    "else:\n",
    "    B = GetDatePairs(start=x.group(0),end=(datetime.today()).strftime(\"%Y-%m-%d\"))\n",
    "    \n",
    "print(f\"Start: {B[0][0]}, End:{B[-1][1]}\")\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: 2024-11-01 00:00:00, End:2026-01-23 00:00:00\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T12:54:47.263860640Z",
     "start_time": "2026-01-24T12:54:47.246627427Z"
    }
   },
   "source": [
    "snp500 = None\n",
    "filepath = Path(\"./data/sp500_companies.csv\")\n",
    "if(False==filepath.is_file()):\n",
    "  headers = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/139.0.0.0 Safari/537.36'}\n",
    "  html_data=requests.get('https://en.wikipedia.org/wiki/List_of_S%26P_500_companies',headers=headers).text\n",
    "  beautiful_soup=BeautifulSoup(html_data, \"html.parser\")\n",
    "  tables = beautiful_soup.find_all('table')\n",
    "  \n",
    "  S_P_500_companies = list([])\n",
    "\n",
    "  for row in tables[1].tbody.find_all(\"tr\"):\n",
    "      col = row.find_all(\"td\")\n",
    "      if (col != []):\n",
    "          Symbol = col[0].text.strip().replace('\\n','')\n",
    "          Security = col[1].text.strip().replace('\\n','')\n",
    "          Sector = col[2].text.strip().replace('\\n','')\n",
    "          Sub_Industry = col[3].text.strip().replace('\\n','')\n",
    "          Headquarters_Location = col[4].text.strip().replace('\\n','')\n",
    "          Date_first = col[5].text.strip().replace('\\n','')\n",
    "          CIK = col[6].text.strip().replace('\\n','')\n",
    "          Founded = col[7].text.strip().replace('\\n','')\n",
    "          S_P_500_companies.append({\"Symbol\":Symbol, \"Security\":Security, \"Sector\":Sector, \"Sub-Industry\":Sub_Industry,\n",
    "            \"Headquarters\":Headquarters_Location,\"Date-Added\":Date_first,\"CIK\":CIK,\"Founded\":Founded})\n",
    "  snp500 = pd.DataFrame(data=S_P_500_companies)\n",
    "  snp500.Symbol = snp500.Symbol.str.replace('.','-') \n",
    "  snp500.to_csv('./data/sp500_companies.csv',index=False)\n",
    "else:\n",
    "   snp500 = pd.read_csv('./data/sp500_companies.csv')"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T12:54:49.037408752Z",
     "start_time": "2026-01-24T12:54:48.992537450Z"
    }
   },
   "source": [
    "snp500.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  Symbol             Security                  Sector  \\\n",
       "0    MMM                   3M             Industrials   \n",
       "1    AOS          A. O. Smith             Industrials   \n",
       "2    ABT  Abbott Laboratories             Health Care   \n",
       "3   ABBV               AbbVie             Health Care   \n",
       "4    ACN            Accenture  Information Technology   \n",
       "\n",
       "                     Sub-Industry             Headquarters  Date-Added  \\\n",
       "0        Industrial Conglomerates    Saint Paul, Minnesota  1957-03-04   \n",
       "1               Building Products     Milwaukee, Wisconsin  2017-07-26   \n",
       "2           Health Care Equipment  North Chicago, Illinois  1957-03-04   \n",
       "3                   Biotechnology  North Chicago, Illinois  2012-12-31   \n",
       "4  IT Consulting & Other Services          Dublin, Ireland  2011-07-06   \n",
       "\n",
       "       CIK      Founded  \n",
       "0    66740         1902  \n",
       "1    91142         1916  \n",
       "2     1800         1888  \n",
       "3  1551152  2013 (1888)  \n",
       "4  1467373         1989  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Security</th>\n",
       "      <th>Sector</th>\n",
       "      <th>Sub-Industry</th>\n",
       "      <th>Headquarters</th>\n",
       "      <th>Date-Added</th>\n",
       "      <th>CIK</th>\n",
       "      <th>Founded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MMM</td>\n",
       "      <td>3M</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>Industrial Conglomerates</td>\n",
       "      <td>Saint Paul, Minnesota</td>\n",
       "      <td>1957-03-04</td>\n",
       "      <td>66740</td>\n",
       "      <td>1902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AOS</td>\n",
       "      <td>A. O. Smith</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>Building Products</td>\n",
       "      <td>Milwaukee, Wisconsin</td>\n",
       "      <td>2017-07-26</td>\n",
       "      <td>91142</td>\n",
       "      <td>1916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABT</td>\n",
       "      <td>Abbott Laboratories</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Health Care Equipment</td>\n",
       "      <td>North Chicago, Illinois</td>\n",
       "      <td>1957-03-04</td>\n",
       "      <td>1800</td>\n",
       "      <td>1888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABBV</td>\n",
       "      <td>AbbVie</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Biotechnology</td>\n",
       "      <td>North Chicago, Illinois</td>\n",
       "      <td>2012-12-31</td>\n",
       "      <td>1551152</td>\n",
       "      <td>2013 (1888)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACN</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>IT Consulting &amp; Other Services</td>\n",
       "      <td>Dublin, Ireland</td>\n",
       "      <td>2011-07-06</td>\n",
       "      <td>1467373</td>\n",
       "      <td>1989</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T12:54:49.770397540Z",
     "start_time": "2026-01-24T12:54:49.729545002Z"
    }
   },
   "source": [
    "def MungeData(sym, spy, start, end):\n",
    "    try:\n",
    "        if(spy is None):\n",
    "            stock = yf.Ticker('^GSPC')\n",
    "            stockhist = stock.history(start=start,end=end)\n",
    "            spy = stockhist[['Open', 'High', 'Low', 'Close', 'Volume']].copy().pct_change(fill_method=None)+1\n",
    "\n",
    "        stock = yf.Ticker(sym)\n",
    "        stockhist = stock.history(start=start,end=end)\n",
    "        x = stockhist[['Open', 'High', 'Low', 'Close', 'Volume']].copy().pct_change(fill_method=None)+1\n",
    "        x /= spy\n",
    "        x = np.log(x)\n",
    "        x.insert(0,'Days',(x.index-x.index[0]).days)\n",
    "        for c in ['Open','Close','High','Low','Volume']:\n",
    "            x[c+'_Div'] = x[c].diff()/x['Days'].diff()\n",
    "            x[c+'_Div2'] = x[c+'_Div'].diff()/x['Days'].diff()\n",
    "            for i in [7,14,21,28]:\n",
    "                x[c+'_'+str(i)+'_MN'] = x[c].rolling(pd.Timedelta(days=i)).mean()\n",
    "                x[c+'_'+str(i)+'_SD'] = (x[c].rolling(pd.Timedelta(days=i)).std())\n",
    "\n",
    "        _ = x.pop('Days')\n",
    "        x.insert(0,\"Sym\",sym)\n",
    "        x['Target'] = x.groupby('Sym').Close.shift(-1).fillna(-999)\n",
    "        x.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "        x.dropna(inplace=True)\n",
    "        \n",
    "        return x, spy\n",
    "    except:\n",
    "        return None, spy"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T12:55:55.594402034Z",
     "start_time": "2026-01-24T12:54:51.079627972Z"
    }
   },
   "source": [
    "start = B[0][0].strftime(\"%Y-%m-%d\")\n",
    "end = B[-1][1].strftime(\"%Y-%m-%d\")\n",
    "print(start,end)\n",
    "spy = None\n",
    "g = []\n",
    "for c in tqdm(list(snp500.Symbol.values)):\n",
    "\n",
    "    l,spy = MungeData(c, spy, (datetime.strptime(start,\"%Y-%m-%d\")-timedelta(weeks=5)).strftime(\"%Y-%m-%d\"), end)#Requred to ensure all  rolling values are populated\n",
    "    \n",
    "    if l is not None:\n",
    "        g.append(l)\n",
    "  \n",
    "o= pd.concat(g, axis=0)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-01 2026-01-23\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/503 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e01c5737b0d1408ca57eea81e590f71a"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T13:47:04.451302200Z",
     "start_time": "2026-01-24T12:55:55.596730728Z"
    }
   },
   "source": [
    "gpModel = GPTiny()\n",
    "for start, end in tqdm(B):\n",
    "    filepath = Path('./dailies_test/top_close_250_'+start.strftime(\"%Y-%m-%d\")+'_'+end.strftime(\"%Y-%m-%d\")+'.csv')\n",
    "    if(False==filepath.is_file()):\n",
    "        #print(start.strftime(\"%Y-%m-%d\"),end.strftime(\"%Y-%m-%d\"))\n",
    "        mask = (o.index >= start.strftime(\"%Y-%m-%d\")) & (o.index < end.strftime(\"%Y-%m-%d\"))\n",
    "        x = o[mask].copy()\n",
    "        #print(x.shape)\n",
    "        wset = []\n",
    "        lset = []\n",
    "        if(x.shape[0]>0):\n",
    "            #print(x.shape)\n",
    "            for gp in range(10):\n",
    "                t = x[['Sym']].copy()\n",
    "                if(gp==0):\n",
    "                    t['Target'] = gpModel.GPI(x)\n",
    "                elif(gp==1):\n",
    "                    t['Target'] = gpModel.GPII(x)\n",
    "                elif(gp==2):\n",
    "                    t['Target'] = gpModel.GPIII(x)\n",
    "                elif(gp==3):\n",
    "                    t['Target'] = gpModel.GPIV(x)\n",
    "                elif(gp==4):\n",
    "                    t['Target'] = gpModel.GPV(x)\n",
    "                if(gp==5):\n",
    "                    t['Target'] = gpModel.GPVI(x)\n",
    "                elif(gp==6):\n",
    "                    t['Target'] = gpModel.GPVII(x)\n",
    "                elif(gp==7):\n",
    "                    t['Target'] = gpModel.GPVIII(x)\n",
    "                elif(gp==8):\n",
    "                    t['Target'] = gpModel.GPIX(x)\n",
    "                else:\n",
    "                    t['Target'] = gpModel.GPX(x)\n",
    "\n",
    "                w = t.reset_index().pivot(index='Date',columns='Sym',values='Target')\n",
    "\n",
    "                w1 = pd.DataFrame({n: w.T[col].nlargest(250).index.tolist()\n",
    "                                for n, col in enumerate(w.T)}).T\n",
    "                l1 = pd.DataFrame({n: w.T[col].nsmallest(250).index.tolist()\n",
    "                                for n, col in enumerate(w.T)}).T\n",
    "                wset.append(w1.values[0])\n",
    "                lset.append(l1.values[0])    \n",
    "\n",
    "                \n",
    "            wsubset = pd.DataFrame(data={'Sym':list(set.intersection(*map(set,wset)))})\n",
    "            lsubset = pd.DataFrame(data={'Sym':list(set.intersection(*map(set,lset)))})\n",
    "\n",
    "            wstd = {}\n",
    "            lstd = {}\n",
    "            for sym in wsubset.Sym.values:\n",
    "                mask = (o.index >= start.strftime(\"%Y-%m-%d\")) & (o.index < end.strftime(\"%Y-%m-%d\"))\n",
    "                x = o[mask].copy()\n",
    "                x = x[x['Sym'] == sym]\n",
    "                v = [gpModel.GPI(x),gpModel.GPII(x),gpModel.GPIII(x),gpModel.GPIV(x),gpModel.GPV(x),\n",
    "                     gpModel.GPVI(x),gpModel.GPVII(x),gpModel.GPVIII(x),gpModel.GPIX(x),gpModel.GPX(x)]\n",
    "                wstd[sym] = [np.std(v),np.min(v),np.mean(v),np.max(v)]\n",
    "            for sym in lsubset.Sym.values:\n",
    "                mask = (o.index >= start.strftime(\"%Y-%m-%d\")) & (o.index < end.strftime(\"%Y-%m-%d\"))\n",
    "                x = o[mask].copy()\n",
    "                x = x[x['Sym'] == sym]\n",
    "                v = [gpModel.GPI(x),gpModel.GPII(x),gpModel.GPIII(x),gpModel.GPIV(x),gpModel.GPV(x),\n",
    "                     gpModel.GPVI(x),gpModel.GPVII(x),gpModel.GPVIII(x),gpModel.GPIX(x),gpModel.GPX(x)]\n",
    "                lstd[sym] = [np.std(v),np.min(v),np.mean(v),np.max(v)]\n",
    "        \n",
    "            w = pd.DataFrame.from_dict(wstd,orient='index',columns=['Std','Mi','Mn','Ma'])\n",
    "            w.index.name = 'Sym'\n",
    "            w.to_csv('./dailies_test/top_close_250_'+start.strftime(\"%Y-%m-%d\")+'_'+end.strftime(\"%Y-%m-%d\")+'.csv')\n",
    "            l = pd.DataFrame.from_dict(lstd,orient='index',columns=['Std','Mi','Mn','Ma'])\n",
    "            l.index.name = 'Sym'\n",
    "            l.to_csv('./dailies_test/bottom_close_250_'+start.strftime(\"%Y-%m-%d\")+'_'+end.strftime(\"%Y-%m-%d\")+'.csv')\n",
    "            "
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/305 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "90a7a0bbb0e340e5a8eba188b10644bc"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T13:47:04.610233175Z",
     "start_time": "2026-01-24T13:47:04.452717129Z"
    }
   },
   "source": "",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-22 00:00:00 2026-01-23 00:00:00\n",
      "Top:\n",
      "https://uk.finance.yahoo.com/quote/IP,YUM,RTX,HAL,ECL,DLTR,KKR,GE,AVB,ITW,SYY,BA,WAB,O,SO,MAR,HII,VRSN,SNPS,IDXX,DXCM,PM,TDG,PEP,MPC,CTAS,APA,HBAN,TECH,NFLX,ROST,TER,GD/\n",
      "Bottom:\n",
      "https://uk.finance.yahoo.com/quote/STT,XYZ,LKQ,JCI,KEYS,SCHW,BAC,RJF,EQT,TSLA,KR,BSX,VRTX,ADI,GPC,REGN,INVH,EME,TT,ON,C,MPWR,DDOG,ANET,PPG,WMT,TXT,AMGN,DVA,BIIB,FSLR,ABNB,EXPD,NVR,PNR,GOOGL,NRG,ORLY,TRV,TSCO,MTB,ABBV,STLD,NVDA,EXE,TTD/\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T14:09:26.061447241Z",
     "start_time": "2026-01-24T14:09:25.993131286Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start, end = B[-1]\n",
    "print(start,end)\n",
    "bottom = pd.read_csv('./dailies_test/bottom_close_250_'+start.strftime(\"%Y-%m-%d\")+'_'+end.strftime(\"%Y-%m-%d\")+'.csv')\n",
    "top = pd.read_csv('./dailies_test/top_close_250_'+start.strftime(\"%Y-%m-%d\")+'_'+end.strftime(\"%Y-%m-%d\")+'.csv')\n",
    "print(\"Top:\")\n",
    "if(len(top.Sym)):\n",
    "    print('https://uk.finance.yahoo.com/quote/{0}/'.format(','.join(top.Sym.values)))\n",
    "else:\n",
    "    print(\"No Recommendations\")\n",
    "print(\"Bottom:\")\n",
    "if(len(bottom.Sym)):\n",
    "    print('https://uk.finance.yahoo.com/quote/{0}/'.format(','.join(bottom.Sym.values)))\n",
    "else:\n",
    "    print(\"No Recommendations\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-22 00:00:00 2026-01-23 00:00:00\n",
      "Top:\n",
      "https://uk.finance.yahoo.com/quote/IP,YUM,RTX,HAL,ECL,DLTR,KKR,GE,AVB,ITW,SYY,BA,WAB,O,SO,MAR,HII,VRSN,SNPS,IDXX,DXCM,PM,TDG,PEP,MPC,CTAS,APA,HBAN,TECH,NFLX,ROST,TER,GD/\n",
      "Bottom:\n",
      "https://uk.finance.yahoo.com/quote/STT,XYZ,LKQ,JCI,KEYS,SCHW,BAC,RJF,EQT,TSLA,KR,BSX,VRTX,ADI,GPC,REGN,INVH,EME,TT,ON,C,MPWR,DDOG,ANET,PPG,WMT,TXT,AMGN,DVA,BIIB,FSLR,ABNB,EXPD,NVR,PNR,GOOGL,NRG,ORLY,TRV,TSCO,MTB,ABBV,STLD,NVDA,EXE,TTD/\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
